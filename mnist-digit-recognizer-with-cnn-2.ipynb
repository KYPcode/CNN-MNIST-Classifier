{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.10","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# MNIST - Digit Recognizer Kaggle Competition with CNN","metadata":{}},{"cell_type":"markdown","source":"What you will find in this notebook:\n\n* Case study of the application and optimization of a CNN\n* Explanation of the functioning of the CNN and the different choices made\n___\n**Disclaimer**: The purpose of this notebook is simply to clarify my thoughts by sharing them so that they may be useful to others. I don't claim to be flawless so if there are any corrections in my explanations or code that you feel are needed, please feel free to let me know.","metadata":{}},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nimport cv2\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import GlobalAveragePooling2D, Dense\nimport tensorflow as tf\nfrom keras_tuner import Hyperband\nfrom kerastuner.engine.hyperparameters import HyperParameters","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-20T06:32:36.062683Z","iopub.execute_input":"2023-05-20T06:32:36.063093Z","iopub.status.idle":"2023-05-20T06:32:45.404455Z","shell.execute_reply.started":"2023-05-20T06:32:36.063050Z","shell.execute_reply":"2023-05-20T06:32:45.403456Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.23.5\n  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Importing and splitting data","metadata":{}},{"cell_type":"code","source":"raw_dataset = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\nraw_dataset_images = raw_dataset.iloc[:, 1:]\nraw_dataset_label = raw_dataset.iloc[:, 0]\n\n\ntraining_data_images, testing_data_images, training_data_label, testing_data_label = train_test_split(\n    raw_dataset_images, raw_dataset_label, test_size=0.2, random_state=0)\n\ntraining_data_label = training_data_label.astype(int)\ntesting_data_label = testing_data_label.astype(int)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T06:32:45.406277Z","iopub.execute_input":"2023-05-20T06:32:45.406921Z","iopub.status.idle":"2023-05-20T06:32:49.603913Z","shell.execute_reply.started":"2023-05-20T06:32:45.406886Z","shell.execute_reply":"2023-05-20T06:32:49.602980Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"markdown","source":"## Resizing each image to be in 28 x 28","metadata":{}},{"cell_type":"code","source":"reshaped_train_df = training_data_images.values.reshape(-1, 28, 28, 1)\nreshaped_test_df = testing_data_images.values.reshape(-1, 28, 28, 1)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2023-05-20T06:33:27.255720Z","iopub.execute_input":"2023-05-20T06:33:27.256627Z","iopub.status.idle":"2023-05-20T06:33:27.262299Z","shell.execute_reply.started":"2023-05-20T06:33:27.256577Z","shell.execute_reply":"2023-05-20T06:33:27.261144Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"markdown","source":"## Generating more data to train","metadata":{}},{"cell_type":"markdown","source":"To increase the number of training images, it is possible to do Image Augmentation. For this, random transformations (rotation, resizing, shift, zoom, horizontal/vertical reversal) will be applied to each image which will add variability to the initial dataset thus improving the performance and generalization of the model. With Keras, ```ImageDataGenerator``` function allows to realize these transformations.","metadata":{}},{"cell_type":"code","source":"datagen = ImageDataGenerator(\n    rotation_range=30,\n    zoom_range=0.20,\n    width_shift_range=False,\n    height_shift_range=False\n)\n\ndatagen.fit(reshaped_train_df)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T07:40:53.230511Z","iopub.execute_input":"2023-05-20T07:40:53.230881Z","iopub.status.idle":"2023-05-20T07:40:53.389813Z","shell.execute_reply.started":"2023-05-20T07:40:53.230837Z","shell.execute_reply":"2023-05-20T07:40:53.388544Z"},"trusted":true},"execution_count":22,"outputs":[]},{"cell_type":"markdown","source":"## Building CNN","metadata":{}},{"cell_type":"markdown","source":"This CNN is built quite classically around the following structure:\n\n**Convolutional Layers:**\nConvolutional layers exploit local patterns and spatial relationships in images. This enables the network to capture local features and reduce computational complexity. Multiple convolutional layers in a CNN architecture (like this one) offer hierarchical feature extraction, increased receptive fields, and non-linear feature composition. Each ``conv2`` layer builds upon lower-level features, learning more complex and abstract representations.\n\n**MaxPooling Layers:**\nAfter each convolutional layer, a maxpooling layer (MaxPooling2D) with a 2x2 pooling window is applied to reduce the feature map's spatial resolution.\n\n**Flatten Layer:**\nThe flatten layer takes the multi-dimensional feature maps produced by the `Conv2D`/`MaxPooling` layers and converts them into a flat vector. This allows the subsequent layers to easily process the information and transmit it to the following `Dense` layer.\n\n**Dense Layers:**\nDense layers are responsible for learning complex relationships between the input features and the output classes.\n\n**Output Layer:**\nThe output Dense layer consists of 10 neurons corresponding to the 10 number types in the MNIST dataset.\n\n___\n**Regularization and Optimization:**\n- L2 regularization is applied to the convolutional layers weights to mitigate overfitting (encouraged to prioritize simpler and smoother weight configurations).\n- The Adam optimizer is employed with a learning rate determined by the Float hyperparameter to update the model weights during training.\n- The \"sparse categorical crossentropy\" loss function is used, suitable for multiclass classification.","metadata":{}},{"cell_type":"code","source":"def model_building(hp_optimizer):\n    model = keras.Sequential()\n    model.add(keras.layers.Conv2D(hp_optimizer.Choice('filters_1', values=[8, 16, 24, 32, 40, 48, 56, 64]), 3, activation=\"relu\", input_shape=(28, 28, 1), padding=\"same\", kernel_regularizer=keras.regularizers.L2(0.0005)))\n    model.add(keras.layers.Conv2D(hp_optimizer.Choice('filters_2', values=[16, 32, 48, 64, 80, 96, 112, 128]), 3, activation=\"relu\", padding=\"same\", kernel_regularizer=keras.regularizers.L2(0.0005)))\n    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(keras.layers.Conv2D(hp_optimizer.Choice('filters_3', values=[32, 64, 96, 128, 160, 192, 224, 256]), 3, activation=\"relu\", padding=\"same\", kernel_regularizer=keras.regularizers.L2(0.0005)))\n    model.add(keras.layers.Conv2D(hp_optimizer.Choice('filters_4', values=[64, 128, 192, 256, 320, 384, 448, 512]), 3, activation=\"relu\", padding=\"same\", kernel_regularizer=keras.regularizers.L2(0.0005)))\n    model.add(keras.layers.MaxPooling2D(pool_size=(2, 2)))\n    model.add(keras.layers.Flatten())\n    model.add(Dense(hp_optimizer.Int('units_1', min_value=32, max_value=512, step=32), activation='relu'))\n    model.add(Dense(hp_optimizer.Int('units_2', min_value=32, max_value=512, step=32), activation='relu'))\n    model.add(Dense(10, activation='softmax'))\n    model.compile(optimizer=keras.optimizers.Adam(hp_optimizer.Float('learning_rate', min_value=1e-4, max_value=1e-2, sampling='log')), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n    return model","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Optimizing hyper parameters\n\nNeural networks, including their constituent layers, rely on several hyperparameters that likely hide optimal values for achieving better performance. To simplify the process of finding these optimal values, various packages such as ``keras_tuner`` offer optimization algorithms like Random Search, **Hyperband**, and Bayesian Optimization, which perform multiple trials to converge on the best set of hyperparameters. \n\nTo incorporate this optimization process into our neural network, we need to define a function that specifies the model architecture (``model_building`` here). This function should include the hyperparameters to be optimized, along with the corresponding intervals of values to be tested for each parameter (as it was done in the ``model_building`` function).\n\n**Note:** The ``EarlyStopping`` callback helps prevent overfitting and saves computational resources by stopping the training process early when certain criteria are met (stops the training if the accuracy does not improve over a certain number of epochs).","metadata":{}},{"cell_type":"code","source":"early_stopping = keras.callbacks.EarlyStopping(monitor=\"val_loss\",patience=5,restore_best_weights=True)\n\nhyperparameters = HyperParameters()\n\ntuner = Hyperband(\n    model_building,\n    objective='val_accuracy',\n    max_epochs=20,\n    factor=3,\n    seed=123,\n    hyperparameters=hyperparameters,\n    directory='/kaggle/working/',\n    project_name='MNIST_comp'\n)\n\ntuner.search(reshaped_train_df, training_data_label, validation_data=(reshaped_test_df, testing_data_label), epochs=20,callbacks=[early_stopping])\n\nbest_model = tuner.get_best_models(num_models=1)[0]\nbest_hyperparameters = tuner.get_best_hyperparameters(num_trials=1)[0]\n","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(\"[RESULT] optimal number of filters in conv2D layer 1: {}\".format(\nbest_hyperparameters.get(\"filters_1\")))\nprint(\"[RESULT] optimal number of filters in conv2D layer 2: {}\".format(\nbest_hyperparameters.get(\"filters_2\")))\nprint(\"[RESULT] optimal number of filters in conv2D layer 3: {}\".format(\nbest_hyperparameters.get(\"filters_3\")))\nprint(\"[RESULT] optimal number of filters in conv2D layer 4: {}\".format(\nbest_hyperparameters.get(\"filters_4\")))\nprint(\"[RESULT] optimal number of units in dense layer 1: {}\".format(\nbest_hyperparameters.get(\"units_1\")))\nprint(\"[RESULT] optimal number of units in dense layer 2: {}\".format(\nbest_hyperparameters.get(\"units_2\")))\nprint(\"[RESULT] optimal learning rate: {:.4f}\".format(\nbest_hyperparameters.get(\"learning_rate\")))","metadata":{"execution":{"iopub.status.busy":"2023-05-20T07:19:10.864898Z","iopub.execute_input":"2023-05-20T07:19:10.865260Z","iopub.status.idle":"2023-05-20T07:19:10.872399Z","shell.execute_reply.started":"2023-05-20T07:19:10.865231Z","shell.execute_reply":"2023-05-20T07:19:10.871421Z"},"jupyter":{"source_hidden":true},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"[RESULT] optimal number of filters in conv2D layer 1: 40\n[RESULT] optimal number of filters in conv2D layer 2: 112\n[RESULT] optimal number of filters in conv2D layer 3: 160\n[RESULT] optimal number of filters in conv2D layer 4: 384\n[RESULT] optimal number of units in dense layer 1: 288\n[RESULT] optimal number of units in dense layer 2: 32\n[RESULT] optimal learning rate: 0.0005\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Now that the optimal parameters are known, it is a matter of applying them to our data set with the image augmentation in addition:","metadata":{}},{"cell_type":"code","source":"best_model.compile(optimizer=best_model.optimizer,\n                   loss=best_model.loss,\n                   metrics='accuracy')\nbest_model.fit(datagen.flow(reshaped_train_df, training_data_label, batch_size=300), batch_size=300,epochs=30,\n          validation_data=(reshaped_test_df, testing_data_label),\n          verbose=1, shuffle=True)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T08:03:06.753317Z","iopub.execute_input":"2023-05-20T08:03:06.753687Z","iopub.status.idle":"2023-05-20T08:12:31.233946Z","shell.execute_reply.started":"2023-05-20T08:03:06.753658Z","shell.execute_reply":"2023-05-20T08:12:31.232884Z"},"trusted":true},"execution_count":32,"outputs":[{"name":"stdout","text":"Epoch 1/30\n","output_type":"stream"},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/tensorflow/python/data/ops/structured_function.py:256: UserWarning: Even though the `tf.config.experimental_run_functions_eagerly` option is set, this option does not apply to tf.data functions. To force eager execution of tf.data functions, please use `tf.data.experimental.enable_debug_mode()`.\n  warnings.warn(\n","output_type":"stream"},{"name":"stdout","text":"112/112 [==============================] - 19s 168ms/step - loss: 0.0278 - accuracy: 0.9936 - val_loss: 0.0229 - val_accuracy: 0.9952\nEpoch 2/30\n112/112 [==============================] - 19s 167ms/step - loss: 0.0289 - accuracy: 0.9931 - val_loss: 0.0237 - val_accuracy: 0.9952\nEpoch 3/30\n112/112 [==============================] - 19s 166ms/step - loss: 0.0289 - accuracy: 0.9933 - val_loss: 0.0227 - val_accuracy: 0.9958\nEpoch 4/30\n112/112 [==============================] - 18s 162ms/step - loss: 0.0272 - accuracy: 0.9939 - val_loss: 0.0242 - val_accuracy: 0.9951\nEpoch 5/30\n112/112 [==============================] - 19s 166ms/step - loss: 0.0273 - accuracy: 0.9935 - val_loss: 0.0248 - val_accuracy: 0.9952\nEpoch 6/30\n112/112 [==============================] - 18s 164ms/step - loss: 0.0278 - accuracy: 0.9938 - val_loss: 0.0293 - val_accuracy: 0.9936\nEpoch 7/30\n112/112 [==============================] - 18s 160ms/step - loss: 0.0249 - accuracy: 0.9945 - val_loss: 0.0245 - val_accuracy: 0.9954\nEpoch 8/30\n112/112 [==============================] - 18s 164ms/step - loss: 0.0285 - accuracy: 0.9935 - val_loss: 0.0240 - val_accuracy: 0.9948\nEpoch 9/30\n112/112 [==============================] - 18s 164ms/step - loss: 0.0251 - accuracy: 0.9947 - val_loss: 0.0257 - val_accuracy: 0.9949\nEpoch 10/30\n112/112 [==============================] - 18s 163ms/step - loss: 0.0270 - accuracy: 0.9939 - val_loss: 0.0253 - val_accuracy: 0.9950\nEpoch 11/30\n112/112 [==============================] - 19s 168ms/step - loss: 0.0256 - accuracy: 0.9941 - val_loss: 0.0293 - val_accuracy: 0.9926\nEpoch 12/30\n112/112 [==============================] - 20s 175ms/step - loss: 0.0273 - accuracy: 0.9936 - val_loss: 0.0261 - val_accuracy: 0.9946\nEpoch 13/30\n112/112 [==============================] - 20s 174ms/step - loss: 0.0252 - accuracy: 0.9942 - val_loss: 0.0258 - val_accuracy: 0.9950\nEpoch 14/30\n112/112 [==============================] - 19s 165ms/step - loss: 0.0237 - accuracy: 0.9948 - val_loss: 0.0258 - val_accuracy: 0.9948\nEpoch 15/30\n112/112 [==============================] - 18s 164ms/step - loss: 0.0257 - accuracy: 0.9941 - val_loss: 0.0242 - val_accuracy: 0.9950\nEpoch 16/30\n112/112 [==============================] - 18s 163ms/step - loss: 0.0239 - accuracy: 0.9945 - val_loss: 0.0270 - val_accuracy: 0.9943\nEpoch 17/30\n112/112 [==============================] - 19s 168ms/step - loss: 0.0268 - accuracy: 0.9940 - val_loss: 0.0241 - val_accuracy: 0.9945\nEpoch 18/30\n112/112 [==============================] - 19s 165ms/step - loss: 0.0246 - accuracy: 0.9944 - val_loss: 0.0239 - val_accuracy: 0.9951\nEpoch 19/30\n112/112 [==============================] - 19s 166ms/step - loss: 0.0240 - accuracy: 0.9946 - val_loss: 0.0247 - val_accuracy: 0.9950\nEpoch 20/30\n112/112 [==============================] - 19s 171ms/step - loss: 0.0249 - accuracy: 0.9946 - val_loss: 0.0247 - val_accuracy: 0.9955\nEpoch 21/30\n112/112 [==============================] - 19s 169ms/step - loss: 0.0244 - accuracy: 0.9947 - val_loss: 0.0242 - val_accuracy: 0.9961\nEpoch 22/30\n112/112 [==============================] - 19s 171ms/step - loss: 0.0261 - accuracy: 0.9938 - val_loss: 0.0251 - val_accuracy: 0.9954\nEpoch 23/30\n112/112 [==============================] - 19s 169ms/step - loss: 0.0238 - accuracy: 0.9950 - val_loss: 0.0240 - val_accuracy: 0.9950\nEpoch 24/30\n112/112 [==============================] - 19s 170ms/step - loss: 0.0239 - accuracy: 0.9947 - val_loss: 0.0246 - val_accuracy: 0.9948\nEpoch 25/30\n112/112 [==============================] - 19s 171ms/step - loss: 0.0235 - accuracy: 0.9952 - val_loss: 0.0249 - val_accuracy: 0.9951\nEpoch 26/30\n112/112 [==============================] - 19s 171ms/step - loss: 0.0252 - accuracy: 0.9946 - val_loss: 0.0245 - val_accuracy: 0.9951\nEpoch 27/30\n112/112 [==============================] - 19s 173ms/step - loss: 0.0236 - accuracy: 0.9950 - val_loss: 0.0243 - val_accuracy: 0.9945\nEpoch 28/30\n112/112 [==============================] - 19s 171ms/step - loss: 0.0230 - accuracy: 0.9952 - val_loss: 0.0240 - val_accuracy: 0.9948\nEpoch 29/30\n112/112 [==============================] - 19s 169ms/step - loss: 0.0223 - accuracy: 0.9954 - val_loss: 0.0271 - val_accuracy: 0.9945\nEpoch 30/30\n112/112 [==============================] - 19s 168ms/step - loss: 0.0237 - accuracy: 0.9949 - val_loss: 0.0246 - val_accuracy: 0.9948\n","output_type":"stream"},{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"<keras.callbacks.History at 0x7a68a43eca60>"},"metadata":{}}]},{"cell_type":"markdown","source":"## Submit Prediction","metadata":{}},{"cell_type":"code","source":"raw_test_data = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\n\nresized_test_data = raw_test_data.values.reshape(-1, 28, 28, 1)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T07:46:49.729783Z","iopub.execute_input":"2023-05-20T07:46:49.730764Z","iopub.status.idle":"2023-05-20T07:46:51.702187Z","shell.execute_reply.started":"2023-05-20T07:46:49.730728Z","shell.execute_reply":"2023-05-20T07:46:51.701185Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"code","source":"predictions = best_model.predict(resized_test_data)\npredicted_classes = np.argmax(predictions, axis=1)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T08:41:17.671736Z","iopub.execute_input":"2023-05-20T08:41:17.672461Z","iopub.status.idle":"2023-05-20T08:41:25.259466Z","shell.execute_reply.started":"2023-05-20T08:41:17.672424Z","shell.execute_reply":"2023-05-20T08:41:25.258359Z"},"trusted":true},"execution_count":33,"outputs":[{"name":"stdout","text":"875/875 [==============================] - 7s 8ms/step\n","output_type":"stream"}]},{"cell_type":"code","source":"predicted_classes_df = pd.DataFrame(predicted_classes, columns=[\"Label\"])\npredicted_classes_df['ImageId'] = predicted_classes_df.index + 1\npredicted_classes_df['Label'], predicted_classes_df['ImageId'] = predicted_classes_df['ImageId'], predicted_classes_df['Label']\npredicted_classes_df = predicted_classes_df.rename(columns={'ImageId': 'Label', 'Label': 'ImageId'})\npredicted_classes_df.to_csv('/kaggle/working/test_output.csv', index=False)","metadata":{"execution":{"iopub.status.busy":"2023-05-20T08:41:25.261446Z","iopub.execute_input":"2023-05-20T08:41:25.261956Z","iopub.status.idle":"2023-05-20T08:41:25.326756Z","shell.execute_reply.started":"2023-05-20T08:41:25.261919Z","shell.execute_reply":"2023-05-20T08:41:25.325623Z"},"trusted":true},"execution_count":34,"outputs":[]}]}
